{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc19e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import whisper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3cc6c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking audio: 100%|██████████| 2/2 [00:00<00:00,  5.08it/s]\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(\"test.mp3\", sr=None)\n",
    "chunk_length = 300 * sr  # 5 min * sample rate\n",
    "# Process in chunks\n",
    "for i in tqdm(range(0, len(y), chunk_length), desc=\"Chunking audio\"):\n",
    "    # Write each chunk as WAV file\n",
    "    sf.write(\n",
    "        f\"./chunks/chunk_{i//chunk_length}.wav\",\n",
    "        y[i:i+chunk_length],\n",
    "        sr,\n",
    "        format='WAV'  # Explicit format\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f64ed17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing chunks:   0%|          | 0/2 [00:00<?, ?it/s]d:\\projects\\Audtio_to_Text_summerizer\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribing chunks:  50%|█████     | 1/2 [00:34<00:34, 34.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chunk_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing chunks: 100%|██████████| 2/2 [00:38<00:00, 19.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chunk_1.wav\n",
      "Transcription saved to transcription.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "chunks_folder = \"./chunks/\"\n",
    "# Transcribe each chunk\n",
    "output_file = \"transcription.txt\"\n",
    "\n",
    "chunk_files = sorted([f for f in os.listdir(chunks_folder) if f.endswith('.wav')])\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for chunk_file in tqdm(chunk_files, desc=\"Transcribing chunks\"):\n",
    "        result = model.transcribe(os.path.join(chunks_folder, chunk_file))\n",
    "        f.write(f\"Transcription for {chunk_file}:\\n\")\n",
    "        f.write(result['text'] + \"\\n\\n\")\n",
    "        print(f\"Processed {chunk_file}\")\n",
    "\n",
    "print(f\"Transcription saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cb78fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\Audtio_to_Text_summerizer\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe909921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\Audtio_to_Text_summerizer\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "010f02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcription.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15a221e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = {}\n",
    "current_chunk = []\n",
    "for line in content.splitlines():\n",
    "    if line.startswith(\"Transcription for\"):\n",
    "        current_chunk = line.split(\" \")[-1].replace(\":\", \"\").replace(\".wav\", \"\")\n",
    "        sections[current_chunk] = \"\"\n",
    "    else:\n",
    "        if current_chunk and line.strip():\n",
    "            sections[current_chunk] += line.strip() + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3e1e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group into 5-minute sections \n",
    "grouped = {}\n",
    "chunks_per_5min = 10  # adjust if your chunks are different\n",
    "sorted_chunks = sorted(sections.keys(), key=lambda x: int(x.split(\"_\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89f02042",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024  # tokens, but roughly ~1024 words for BART\n",
    "for i in range(0, len(sorted_chunks), chunks_per_5min):\n",
    "    group_id = i // chunks_per_5min + 1\n",
    "    start_min = (i * 30) // 60\n",
    "    end_min = ((i + chunks_per_5min) * 30) // 60\n",
    "    section_label = f\"Section {group_id}: Minute {start_min}–{end_min}\"\n",
    "\n",
    "    text_block = \" \".join(sections[ch] for ch in sorted_chunks[i:i+chunks_per_5min])\n",
    "    # Truncate text_block if too long\n",
    "    text_block = text_block[:4000]  # 4000 chars is usually safe for BART\n",
    "\n",
    "    summary = summarizer(text_block, max_length=150, min_length=50, do_sample=False)[0][\"summary_text\"]\n",
    "    grouped[section_label] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ce41f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Section 1: Minute 0–5 ===\n",
      " You need to put in 10,000 hours of work to become an expert at a thing. I think a lot of people in the beginner stage get paralyzed by the choice. I wouldn't say I hate teaching, I tolerate teaching, but it's not like the act of teaching that I like. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sec, summ in grouped.items():\n",
    "    print(f\"\\n=== {sec} ===\\n {summary} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9257617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries saved to summary.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sec, summ in grouped.items():\n",
    "        f.write(f\"=== {sec} ===\\n{summ}\\n\\n\")\n",
    "print(\"Summaries saved to summary.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audtio-to-text-summerizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
